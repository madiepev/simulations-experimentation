<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fine-Tuning Notebook Simulation - Azure AI Lab</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen', 'Ubuntu', 'Cantarell', sans-serif;
            background-color: #fafafa;
            color: #333;
            line-height: 1.6;
        }

        .notebook-header {
            background: linear-gradient(135deg, #0078d4 0%, #106ebe 100%);
            color: white;
            padding: 15px 20px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            position: sticky;
            top: 0;
            z-index: 100;
        }

        .notebook-title {
            font-size: 18px;
            font-weight: 600;
            margin: 0;
        }

        .notebook-subtitle {
            font-size: 14px;
            opacity: 0.9;
            margin-top: 2px;
        }

        .notebook-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        .cell {
            background: white;
            border: 1px solid #e1e5e9;
            border-radius: 8px;
            margin-bottom: 16px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
            overflow: hidden;
            transition: all 0.2s ease;
        }

        .cell:hover {
            box-shadow: 0 2px 8px rgba(0,0,0,0.15);
        }

        .cell-header {
            background: #f8f9fa;
            border-bottom: 1px solid #e1e5e9;
            padding: 8px 12px;
            display: flex;
            align-items: center;
            justify-content: space-between;
            font-size: 12px;
            color: #666;
        }

        .cell-type {
            font-weight: 500;
            display: flex;
            align-items: center;
        }

        .cell-type::before {
            content: '';
            width: 8px;
            height: 8px;
            border-radius: 50%;
            margin-right: 6px;
        }

        .cell-type.markdown::before {
            background: #28a745;
        }

        .cell-type.code::before {
            background: #007acc;
        }

        .cell-content {
            padding: 16px;
        }

        .markdown-cell .cell-content {
            padding: 20px;
        }

        .code-cell {
            position: relative;
        }

        .code-input {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 4px;
            padding: 12px;
            font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
            font-size: 13px;
            line-height: 1.4;
            white-space: pre-wrap;
            overflow-x: auto;
            margin-bottom: 12px;
        }

        .run-button {
            background: #0078d4;
            color: white;
            border: none;
            border-radius: 4px;
            padding: 8px 16px;
            font-size: 12px;
            font-weight: 500;
            cursor: pointer;
            transition: background 0.2s ease;
            display: flex;
            align-items: center;
            gap: 6px;
        }

        .run-button:hover {
            background: #106ebe;
        }

        .run-button:disabled {
            background: #6c757d;
            cursor: not-allowed;
        }

        .run-button.running {
            background: #ffc107;
            color: #000;
        }

        .cell-output {
            margin-top: 12px;
            padding: 12px;
            background: #fff;
            border: 1px solid #e9ecef;
            border-radius: 4px;
            font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
            font-size: 13px;
            line-height: 1.4;
            white-space: pre-wrap;
            display: none;
        }

        .cell-output.show {
            display: block;
            animation: fadeIn 0.3s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .reflection-box {
            margin-top: 16px;
            padding: 16px;
            background: linear-gradient(135deg, #e3f2fd 0%, #f3e5f5 100%);
            border: 1px solid #90caf9;
            border-radius: 8px;
            display: none;
        }

        .reflection-box.show {
            display: block;
            animation: slideDown 0.4s ease;
        }

        @keyframes slideDown {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .reflection-title {
            font-weight: 600;
            color: #1976d2;
            margin-bottom: 8px;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .reflection-title::before {
            content: 'ü§î';
            font-size: 16px;
        }

        .reflection-question {
            color: #333;
            font-size: 14px;
            margin-bottom: 12px;
        }

        .reflection-input {
            width: 100%;
            padding: 8px 12px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 14px;
            resize: vertical;
            min-height: 60px;
        }

        .loading-spinner {
            display: inline-block;
            width: 12px;
            height: 12px;
            border: 2px solid #f3f3f3;
            border-top: 2px solid #0078d4;
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .gradient-header {
            background: linear-gradient(135deg, #034694 0%, #1E8449 50%, #D4AC0D 100%);
            color: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
            margin-bottom: 20px;
        }

        .gradient-header h1 {
            color: #FFF;
            text-shadow: 1px 1px 3px rgba(0,0,0,0.5);
            margin-bottom: 10px;
        }

        .step-button {
            display: flex;
            align-items: center;
            justify-content: left;
            padding: 10px 15px;
            height: 50px;
            background: linear-gradient(90deg, #7873f5 0%, #ff6ec4 100%);
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.12);
            font-size: 1.2em;
            font-weight: bold;
            color: #fff;
            margin: 10px 0;
            text-decoration: none;
        }

        .step-button.completed {
            background: linear-gradient(90deg, #333333 0%, #777777 50%, #BBBBBB 100%);
        }

        .notebook-status {
            position: fixed;
            top: 20px;
            right: 20px;
            background: white;
            padding: 8px 12px;
            border-radius: 20px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            font-size: 12px;
            color: #666;
            z-index: 101;
        }

        .status-dot {
            width: 8px;
            height: 8px;
            background: #28a745;
            border-radius: 50%;
            display: inline-block;
            margin-right: 6px;
        }
    </style>
</head>
<body>
    <div class="notebook-header">
        <div class="notebook-title">01-basic-fine-tuning.ipynb</div>
        <div class="notebook-subtitle">Azure AI Lab ‚Ä¢ Interactive Notebook Simulation</div>
    </div>

    <div class="notebook-status">
        <span class="status-dot"></span>
        Kernel Ready
    </div>

    <div class="notebook-container">
        <!-- Cell 1: Header -->
        <div class="cell markdown-cell">
            <div class="cell-header">
                <span class="cell-type markdown">Markdown</span>
                <span>In [1]:</span>
            </div>
            <div class="cell-content">
                <div class="gradient-header">
                    <h1>üí¨ | Step 2: Customize The Tone & Style With SFT</h1>
                    <p style="font-size: 16px; line-height: 1.6;">
                        We used few shot examples to prompt-engineer a better tone. We used RAG to ground responses in our data. But this keeps growing our prompt lengths (increasing token costs and reduce effective context window available for output). How can we improve the tone and style of our bot with <em>more examples</em> and shorter prompt length?
                    </p>
                </div>
            </div>
        </div>

        <!-- Cell 2: Step Navigation -->
        <div class="cell markdown-cell">
            <div class="cell-header">
                <span class="cell-type markdown">Markdown</span>
                <span>In [2]:</span>
            </div>
            <div class="cell-content">
                <div class="step-button completed">
                    Step 1: Understand Zava Scenarios
                </div>
                <div class="step-button">
                    Step 3: Be More Cost-Effective With Distillation
                </div>
                <div class="step-button">
                    Step 4: Be More Precise with RAFT
                </div>
            </div>
        </div>

        <!-- Cell 3: Environment Check -->
        <div class="cell markdown-cell">
            <div class="cell-header">
                <span class="cell-type markdown">Markdown</span>
                <span>In [3]:</span>
            </div>
            <div class="cell-content">
                <h3>1. Check Environment Variables</h3>
            </div>
        </div>

        <!-- Cell 4: Environment Code -->
        <div class="cell code-cell">
            <div class="cell-header">
                <span class="cell-type code">Code</span>
                <span>In [4]:</span>
            </div>
            <div class="cell-content">
                <div class="code-input">import os

openai_key = os.getenv("AZURE_OPENAI_API_KEY")
openai_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
model_name = "gpt-4.1"
api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2025-02-01-preview")

if not openai_key or not openai_endpoint:
    print("Error: Missing AZURE_OPENAI_KEY or AZURE_OPENAI_ENDPOINT environment variable.")

print("Using Model:", model_name)
print("Using API Version:", api_version)</div>
                <button class="run-button" onclick="runCell(this, 'env-check')">
                    <span>‚ñ∂</span> Run
                </button>
                <div class="cell-output" id="env-check-output">Using Model: gpt-4.1
Using API Version: 2025-02-01-preview</div>
                <div class="reflection-box" id="env-check-reflection">
                    <div class="reflection-title">Reflection Question</div>
                    <div class="reflection-question">Why is it important to check environment variables before starting a fine-tuning job? What could go wrong if these are not properly configured?</div>
                    <textarea class="reflection-input" placeholder="Type your thoughts here..."></textarea>
                </div>
            </div>
        </div>

        <!-- Cell 5: Dataset Validation Header -->
        <div class="cell markdown-cell">
            <div class="cell-header">
                <span class="cell-type markdown">Markdown</span>
                <span>In [5]:</span>
            </div>
            <div class="cell-content">
                <h3>2. Validate Training Dataset</h3>
            </div>
        </div>

        <!-- Cell 6: Dataset Files -->
        <div class="cell code-cell">
            <div class="cell-header">
                <span class="cell-type code">Code</span>
                <span>In [6]:</span>
            </div>
            <div class="cell-content">
                <div class="code-input"># Identify Training and Validation datafiles

training_file = "data/basic_sft_training.jsonl" 
validation_file = "data/basic_sft_validation.jsonl"</div>
                <button class="run-button" onclick="runCell(this, 'dataset-files')">
                    <span>‚ñ∂</span> Run
                </button>
                <div class="cell-output" id="dataset-files-output"># Files configured successfully</div>
                <div class="reflection-box" id="dataset-files-reflection">
                    <div class="reflection-title">Reflection Question</div>
                    <div class="reflection-question">What is the purpose of having separate training and validation files in machine learning? How might the ratio between these datasets affect model performance?</div>
                    <textarea class="reflection-input" placeholder="Type your thoughts here..."></textarea>
                </div>
            </div>
        </div>

        <!-- Cell 7: Load Dataset -->
        <div class="cell code-cell">
            <div class="cell-header">
                <span class="cell-type code">Code</span>
                <span>In [7]:</span>
            </div>
            <div class="cell-content">
                <div class="code-input"># Run preliminary checks

import json

# Load the training set
with open(training_file, 'r', encoding='utf-8') as f:
    training_dataset = [json.loads(line) for line in f]

# Training dataset stats
print("Number of examples in training set:", len(training_dataset))
print("First example in training set:")
for message in training_dataset[0]["messages"]:
    print(message)

# Load the validation set
with open(validation_file, 'r', encoding='utf-8') as f:
    validation_dataset = [json.loads(line) for line in f]

# Validation dataset stats
print("\nNumber of examples in validation set:", len(validation_dataset))
print("First example in validation set:")
for message in validation_dataset[0]["messages"]:
    print(message)</div>
                <button class="run-button" onclick="runCell(this, 'load-dataset')">
                    <span>‚ñ∂</span> Run
                </button>
                <div class="cell-output" id="load-dataset-output">Number of examples in training set: 127
First example in training set:
{'role': 'system', 'content': 'You are Zava, a helpful assistant for a home improvement store. Be polite, factual, and helpful.'}
{'role': 'user', 'content': 'What kind of paint should I use for my kitchen walls?'}
{'role': 'assistant', 'content': 'üé® Great question! For kitchen walls, I recommend semi-gloss or satin paint for easy cleaning and moisture resistance. Would you like specific brand recommendations?'}

Number of examples in validation set: 32
First example in validation set:
{'role': 'system', 'content': 'You are Zava, a helpful assistant for a home improvement store. Be polite, factual, and helpful.'}
{'role': 'user', 'content': 'I need help choosing the right drill bit for concrete'}
{'role': 'assistant', 'content': 'üîß Perfect timing! For concrete, use masonry drill bits with carbide tips. What size holes are you planning to drill?'}</div>
                <div class="reflection-box" id="load-dataset-reflection">
                    <div class="reflection-title">Reflection Question</div>
                    <div class="reflection-question">Looking at the examples, what specific patterns do you notice in the assistant responses? How do these patterns align with the system prompt instructions?</div>
                    <textarea class="reflection-input" placeholder="Type your thoughts here..."></textarea>
                </div>
            </div>
        </div>

        <!-- Cell 8: Token Analysis Header -->
        <div class="cell markdown-cell">
            <div class="cell-header">
                <span class="cell-type markdown">Markdown</span>
                <span>In [8]:</span>
            </div>
            <div class="cell-content">
                <h3>3. Assess Token Counts For Data</h3>
            </div>
        </div>

        <!-- Cell 9: Token Analysis -->
        <div class="cell code-cell">
            <div class="cell-header">
                <span class="cell-type code">Code</span>
                <span>In [9]:</span>
            </div>
            <div class="cell-content">
                <div class="code-input"># Validate token counts

import json
import tiktoken
import numpy as np

encoding = tiktoken.get_encoding("o200k_base") # default encoding for gpt-4o models

def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):
    num_tokens = 0
    for message in messages:
        num_tokens += tokens_per_message
        for key, value in message.items():
            num_tokens += len(encoding.encode(value))
            if key == "name":
                num_tokens += tokens_per_name
    num_tokens += 3
    return num_tokens

def num_assistant_tokens_from_messages(messages):
    num_tokens = 0
    for message in messages:
        if message["role"] == "assistant":
            num_tokens += len(encoding.encode(message["content"]))
    return num_tokens

def print_distribution(values, name):
    print(f"\n#### Distribution of {name}:")
    print(f"min / max: {min(values)}, {max(values)}")
    print(f"mean / median: {np.mean(values):.1f}, {np.median(values)}")
    print(f"p5 / p95: {np.quantile(values, 0.1):.1f}, {np.quantile(values, 0.9):.1f}")

files = [training_file, validation_file]

for file in files:
    print(f"Processing file: {file}")
    with open(file, 'r', encoding='utf-8') as f:
        dataset = [json.loads(line) for line in f]

    total_tokens = []
    assistant_tokens = []

    for ex in dataset:
        messages = ex.get("messages", {})
        total_tokens.append(num_tokens_from_messages(messages))
        assistant_tokens.append(num_assistant_tokens_from_messages(messages))

    print_distribution(total_tokens, "total tokens")
    print_distribution(assistant_tokens, "assistant tokens")
    print('*' * 50)</div>
                <button class="run-button" onclick="runCell(this, 'token-analysis')">
                    <span>‚ñ∂</span> Run
                </button>
                <div class="cell-output" id="token-analysis-output">Processing file: data/basic_sft_training.jsonl

#### Distribution of total tokens:
min / max: 45, 156
mean / median: 78.4, 76.0
p5 / p95: 52.0, 112.0

#### Distribution of assistant tokens:
min / max: 12, 45
mean / median: 23.1, 22.0
p5 / p95: 15.0, 34.0
**************************************************
Processing file: data/basic_sft_validation.jsonl

#### Distribution of assistant tokens:
min / max: 11, 43
mean / median: 22.8, 21.5
p5 / p95: 14.0, 33.0

#### Distribution of total tokens:
min / max: 43, 152
mean / median: 77.2, 75.0
p5 / p95: 51.0, 110.0
**************************************************</div>
                <div class="reflection-box" id="token-analysis-reflection">
                    <div class="reflection-title">Reflection Question</div>
                    <div class="reflection-question">Why is it important to analyze token distributions before fine-tuning? What insights can you draw from the min/max and mean/median values shown above?</div>
                    <textarea class="reflection-input" placeholder="Type your thoughts here..."></textarea>
                </div>
            </div>
        </div>

        <!-- Cell 10: Upload Header -->
        <div class="cell markdown-cell">
            <div class="cell-header">
                <span class="cell-type markdown">Markdown</span>
                <span>In [10]:</span>
            </div>
            <div class="cell-content">
                <h3>4. Upload Fine-Tuning Data To Cloud</h3>
            </div>
        </div>

        <!-- Cell 11: Create Client -->
        <div class="cell code-cell">
            <div class="cell-header">
                <span class="cell-type code">Code</span>
                <span>In [11]:</span>
            </div>
            <div class="cell-content">
                <div class="code-input"># Create Azure OpenAI Client

import os
from openai import AzureOpenAI

client = AzureOpenAI(
  azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT"),
  api_key = os.getenv("AZURE_OPENAI_API_KEY"),
  api_version = os.getenv("AZURE_OPENAI_API_VERSION")
)</div>
                <button class="run-button" onclick="runCell(this, 'create-client')">
                    <span>‚ñ∂</span> Run
                </button>
                <div class="cell-output" id="create-client-output"># Azure OpenAI client created successfully</div>
                <div class="reflection-box" id="create-client-reflection">
                    <div class="reflection-title">Reflection Question</div>
                    <div class="reflection-question">What are the key components needed to create an Azure OpenAI client? Why is each of these components important for authentication and connection?</div>
                    <textarea class="reflection-input" placeholder="Type your thoughts here..."></textarea>
                </div>
            </div>
        </div>

        <!-- Cell 12: Upload Files -->
        <div class="cell code-cell">
            <div class="cell-header">
                <span class="cell-type code">Code</span>
                <span>In [12]:</span>
            </div>
            <div class="cell-content">
                <div class="code-input"># Upload the training and validation dataset files to Azure OpenAI with the SDK.

training_response = client.files.create(
    file = open(training_file, "rb"), purpose="fine-tune"
)
training_file_id = training_response.id

validation_response = client.files.create(
    file = open(validation_file, "rb"), purpose="fine-tune"
)
validation_file_id = validation_response.id

print("Training file ID:", training_file_id)
print("Validation file ID:", validation_file_id)</div>
                <button class="run-button" onclick="runCell(this, 'upload-files')">
                    <span>‚ñ∂</span> Run
                </button>
                <div class="cell-output" id="upload-files-output">Training file ID: file-abc123def456ghi789
Validation file ID: file-xyz789abc123def456</div>
                <div class="reflection-box" id="upload-files-reflection">
                    <div class="reflection-title">Reflection Question</div>
                    <div class="reflection-question">Why do we need to upload our dataset files to the cloud platform before starting fine-tuning? What happens to these files after the fine-tuning job completes?</div>
                    <textarea class="reflection-input" placeholder="Type your thoughts here..."></textarea>
                </div>
            </div>
        </div>

        <!-- Cell 13: Submit Job Header -->
        <div class="cell markdown-cell">
            <div class="cell-header">
                <span class="cell-type markdown">Markdown</span>
                <span>In [13]:</span>
            </div>
            <div class="cell-content">
                <h3>5. Submit The Fine-Tuning Job</h3>
            </div>
        </div>

        <!-- Cell 14: Submit Job -->
        <div class="cell code-cell">
            <div class="cell-header">
                <span class="cell-type code">Code</span>
                <span>In [14]:</span>
            </div>
            <div class="cell-content">
                <div class="code-input"># Submit fine-tuning training job
response = client.fine_tuning.jobs.create(
    training_file=training_file_id,
    validation_file=validation_file_id,
    model="gpt-4.1-2025-04-14",
    seed = 105  # seed parameter controls reproducibility
)

job_id = response.id

print("Job ID:", response.id)
print("Status:", response.status)
print("Model:", response.model)</div>
                <button class="run-button" onclick="runCell(this, 'submit-job')">
                    <span>‚ñ∂</span> Run
                </button>
                <div class="cell-output" id="submit-job-output">Job ID: ftjob-abc123def456ghi789
Status: pending
Model: gpt-4.1-2025-04-14</div>
                <div class="reflection-box" id="submit-job-reflection">
                    <div class="reflection-title">Reflection Question</div>
                    <div class="reflection-question">What is the purpose of the 'seed' parameter in fine-tuning? How does setting a specific seed value affect the reproducibility of your results?</div>
                    <textarea class="reflection-input" placeholder="Type your thoughts here..."></textarea>
                </div>
            </div>
        </div>

        <!-- Cell 15: Track Status Header -->
        <div class="cell markdown-cell">
            <div class="cell-header">
                <span class="cell-type markdown">Markdown</span>
                <span>In [15]:</span>
            </div>
            <div class="cell-content">
                <h3>6. Track Fine-Tuning Job Status</h3>
            </div>
        </div>

        <!-- Cell 16: Track Status -->
        <div class="cell code-cell">
            <div class="cell-header">
                <span class="cell-type code">Code</span>
                <span>In [16]:</span>
            </div>
            <div class="cell-content">
                <div class="code-input"># Track training status

from IPython.display import clear_output
import time

start_time = time.time()

# Get the status of our fine-tuning job.
response = client.fine_tuning.jobs.retrieve(job_id)
status = response.status

print(f'Fine-tuning job {job_id} finished with status: {status}')
print('Elapsed time: 15 minutes 32 seconds')

# List all fine-tuning jobs for this resource.
print('Checking other fine-tune jobs for this resource.')
response = client.fine_tuning.jobs.list()
print(f'Found {len(response.data)} fine-tune jobs.')</div>
                <button class="run-button" onclick="runCell(this, 'track-status')">
                    <span>‚ñ∂</span> Run
                </button>
                <div class="cell-output" id="track-status-output">Fine-tuning job ftjob-abc123def456ghi789 finished with status: succeeded
Elapsed time: 15 minutes 32 seconds
Checking other fine-tune jobs for this resource.
Found 3 fine-tune jobs.</div>
                <div class="reflection-box" id="track-status-reflection">
                    <div class="reflection-title">Reflection Question</div>
                    <div class="reflection-question">This fine-tuning job completed in about 15 minutes. What factors might influence the time it takes to complete a fine-tuning job? How would you handle a job that fails?</div>
                    <textarea class="reflection-input" placeholder="Type your thoughts here..."></textarea>
                </div>
            </div>
        </div>

        <!-- Cell 17: Results Header -->
        <div class="cell markdown-cell">
            <div class="cell-header">
                <span class="cell-type markdown">Markdown</span>
                <span>In [17]:</span>
            </div>
            <div class="cell-content">
                <h3>7. Retrieve Fine-Tuned Model Name</h3>
            </div>
        </div>

        <!-- Cell 18: Get Model -->
        <div class="cell code-cell">
            <div class="cell-header">
                <span class="cell-type code">Code</span>
                <span>In [18]:</span>
            </div>
            <div class="cell-content">
                <div class="code-input"># Retrieve fine_tuned_model name

response = client.fine_tuning.jobs.retrieve(job_id)
fine_tuned_model = response.fine_tuned_model

print("Fine-tuned model name:", fine_tuned_model)
print("Training complete! Ready for deployment.")</div>
                <button class="run-button" onclick="runCell(this, 'get-model')">
                    <span>‚ñ∂</span> Run
                </button>
                <div class="cell-output" id="get-model-output">Fine-tuned model name: ft:gpt-4.1-2025-04-14:zava-assist:basic-sft:abc123
Training complete! Ready for deployment.</div>
                <div class="reflection-box" id="get-model-reflection">
                    <div class="reflection-title">Reflection Question</div>
                    <div class="reflection-question">What does the fine-tuned model name tell you about the model? How would you use this model name in your applications?</div>
                    <textarea class="reflection-input" placeholder="Type your thoughts here..."></textarea>
                </div>
            </div>
        </div>

        <!-- Cell 19: Testing Header -->
        <div class="cell markdown-cell">
            <div class="cell-header">
                <span class="cell-type markdown">Markdown</span>
                <span>In [19]:</span>
            </div>
            <div class="cell-content">
                <h3>8. Test The Fine-Tuned Model</h3>
                <p>Let's test our fine-tuned model with some sample prompts to see how it performs:</p>
                
                <blockquote style="background: #f8f9fa; padding: 15px; border-left: 4px solid #0078d4; margin: 10px 0;">
                    <strong>Prompt 1:</strong> What kind of paint should I buy for my outdoor deck?<br><br>
                    <strong>Response:</strong> ü™µ Deck protection options! Semi-Transparent Deck Stain at $38 enhances wood grain, or Deck & Fence Stain at $36 for UV protection?
                </blockquote>

                <blockquote style="background: #f8f9fa; padding: 15px; border-left: 4px solid #0078d4; margin: 10px 0;">
                    <strong>Prompt 2:</strong> I'm painting over rust - what spray paint should I use?<br><br>
                    <strong>Response:</strong> üëç Right choice! Rust Prevention Spray at $13 applies directly over rust with long-lasting protection. Primer recommendation?
                </blockquote>

                <div style="background: #e8f5e8; padding: 15px; border-radius: 8px; margin: 15px 0;">
                    <h4>üéØ Key Insights</h4>
                    <p>In both examples above we can note that the response now accurately follows our Zava guidelines for "polite, factual and helpful":</p>
                    <ul>
                        <li>Every response starts with an emoji</li>
                        <li>The first sentence is always an acknowledgement of the user ("polite")</li>
                        <li>The next sentence is always an informative segment ("factual")</li>
                        <li>The final sentence is always an offer to follow up ("helpful")</li>
                    </ul>
                    <p>And note that we have the succinct responses we were looking for <em>without adding few-shot examples</em>, making the prompts shorter and thus saving both token costs and processing latency.</p>
                </div>
            </div>
        </div>

        <!-- Cell 20: Next Steps -->
        <div class="cell markdown-cell">
            <div class="cell-header">
                <span class="cell-type markdown">Markdown</span>
                <span>In [20]:</span>
            </div>
            <div class="cell-content">
                <div class="step-button">
                    Next: Be More Cost-Effective With Distillation
                </div>
            </div>
        </div>
    </div>

    <script>
        let cellRunCount = 0;

        function runCell(button, cellId) {
            const outputId = cellId + '-output';
            const reflectionId = cellId + '-reflection';
            const output = document.getElementById(outputId);
            const reflection = document.getElementById(reflectionId);
            
            // Update button state
            button.innerHTML = '<span class="loading-spinner"></span> Running...';
            button.classList.add('running');
            button.disabled = true;
            
            // Simulate execution delay
            setTimeout(() => {
                // Show output
                output.classList.add('show');
                
                // Reset button
                button.innerHTML = '<span>‚ñ∂</span> Run';
                button.classList.remove('running');
                button.disabled = false;
                
                // Show reflection question after a brief delay
                setTimeout(() => {
                    if (reflection) {
                        reflection.classList.add('show');
                    }
                }, 500);
                
                // Update cell counter
                cellRunCount++;
                updateNotebookStatus();
                
            }, Math.random() * 2000 + 1000); // Random delay between 1-3 seconds
        }
        
        function updateNotebookStatus() {
            const statusElement = document.querySelector('.notebook-status');
            if (cellRunCount > 0) {
                statusElement.innerHTML = `<span class="status-dot"></span>Cells Run: ${cellRunCount}`;
            }
        }

        // Add some interactivity to reflection inputs
        document.addEventListener('input', function(e) {
            if (e.target.classList.contains('reflection-input')) {
                if (e.target.value.length > 10) {
                    e.target.style.background = '#f0fff0';
                    e.target.style.borderColor = '#28a745';
                } else {
                    e.target.style.background = '#fff';
                    e.target.style.borderColor = '#ccc';
                }
            }
        });

        // Add keyboard shortcuts
        document.addEventListener('keydown', function(e) {
            // Shift + Enter to run current cell (simplified)
            if (e.shiftKey && e.key === 'Enter') {
                const activeButton = document.querySelector('.run-button:hover');
                if (activeButton) {
                    activeButton.click();
                }
            }
        });
    </script>
</body>
</html>
